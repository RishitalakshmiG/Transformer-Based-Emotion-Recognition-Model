{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishitalakshmiG/Transformer-Based-Emotion-Recognition-Model/blob/main/Transformer_Based_Emotion_Recognition_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p7bAezFkdGM"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qs765u5kl4F"
      },
      "outputs": [],
      "source": [
        "#2\n",
        "path = \"/content/drive/MyDrive/dailydialog.docx\"\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMsQsuh1lArS"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "!pip install python-docx pandas\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGCO23krnC4e"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls -lh \"/content/drive/MyDrive\" | grep dailydialog\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xaa7Dv1CnOlJ"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAJrw4t8nSJV"
      },
      "outputs": [],
      "source": [
        "#6\n",
        "!ls \"/content/drive/MyDrive\"\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awVxsTjPnZBs"
      },
      "outputs": [],
      "source": [
        "#7\n",
        "!ls \"/content/drive/MyDrive/\"\n",
        "\n",
        "3. #Load the CSV with pandas:#\n",
        "import pandas as pd\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/dailydialog.csv\"  # change if inside folder\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "df.head()\n",
        "#working cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm_OL8Oznohy"
      },
      "outputs": [],
      "source": [
        "#8\n",
        "print(df.shape)        # dimensions\n",
        "print(df.columns)      # column names\n",
        "print(df.info())       # info and data types\n",
        "print(df.isnull().sum())  # missing values count\n",
        "\n",
        "#working cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1gAoTjxp81i"
      },
      "outputs": [],
      "source": [
        "#9\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "\n",
        "# Suppose your dataframe is called data\n",
        "# Fix the string so it can be converted to a Python list\n",
        "def str_to_list(s):\n",
        "    # Remove outer brackets if any\n",
        "    s = s.strip()[1:-1]\n",
        "    # Replace multiple spaces with comma\n",
        "    s = re.sub(r\"\\s+\", \",\", s)\n",
        "    # Convert to actual list of ints\n",
        "    return [int(x) for x in s.split(\",\") if x]\n",
        "\n",
        "# Apply to dialog, act, emotion columns\n",
        "df['dialog']\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwQSDaC-qwaQ"
      },
      "outputs": [],
      "source": [
        "#10\n",
        "# Robust parser for dialog/act/emotion columns and flatten to utterance-level df\n",
        "import ast, re\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "import nltk\n",
        "\n",
        "# If you don't have nltk punkt tokenizer installed, uncomment:\n",
        "# nltk.download('punkt')\n",
        "\n",
        "def normalize_quotes(s: str) -> str:\n",
        "    \"\"\"Replace curly quotes and weird unicode apostrophes with ASCII equivalents.\"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "    s = s.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
        "    s = s.replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \"-\")\n",
        "    return s\n",
        "\n",
        "def try_literal_eval(s: str):\n",
        "    \"\"\"Try to parse a string with ast.literal_eval, safely returning None if it fails.\"\"\"\n",
        "    try:\n",
        "        return ast.literal_eval(s)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# Sentence splitter fallback: splits on punctuation (.!?)+ whitespace; preserves abbreviations badly but OK for dialogues.\n",
        "sent_split_re = re.compile(r'(?<=[.!?])\\s+')\n",
        "\n",
        "def split_into_sentences_by_regex(text: str) -> List[str]:\n",
        "    \"\"\"Fallback: split a long string into sentences by punctuation-based regex.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    # normalize multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    parts = re.split(sent_split_re, text)\n",
        "    # strip and remove empty parts\n",
        "    parts = [p.strip() for p in parts if p.strip()]\n",
        "    return parts\n",
        "\n",
        "def parse_possible_dialog_field(raw):\n",
        "    \"\"\"\n",
        "    Given raw value from 'dialog' column, return a list of utterances.\n",
        "    Handles:\n",
        "      - Proper python list string -> ast.literal_eval\n",
        "      - Single-quoted long string -> split by sentence boundary\n",
        "      - Already a list -> return as-is\n",
        "    \"\"\"\n",
        "    if raw is None:\n",
        "        return []\n",
        "    # If it's already a list\n",
        "    if isinstance(raw, list):\n",
        "        return [str(x).strip() for x in raw if str(x).strip()]\n",
        "\n",
        "    # Normalize quotes and whitespace first\n",
        "    s = normalize_quotes(str(raw)).strip()\n",
        "\n",
        "    # Try literal_eval directly (works if it's like \"['utt1', 'utt2']\" or \"['utt1' 'utt2']\" sometimes)\n",
        "    parsed = try_literal_eval(s)\n",
        "    if isinstance(parsed, list):\n",
        "        return [str(x).strip() for x in parsed if str(x).strip()]\n",
        "\n",
        "    # If literal_eval failed: check for pattern where numbers or tokens are space-separated like \"[3 2 3]\" etc.\n",
        "    # For numeric lists (act/emotion) we'll handle elsewhere. For dialog, we check if s starts with [ and ends with ].\n",
        "    if s.startswith('[') and s.endswith(']'):\n",
        "        inner = s[1:-1].strip()\n",
        "        # If inner contains quotes somewhere, try to extract quoted substrings\n",
        "        quoted = re.findall(r\"'(.*?)'|\\\"(.*?)\\\"\", inner)\n",
        "        # quoted is list of tuples: (group1, group2). extract non-empty and strip\n",
        "        quoted_flat = [q[0] if q[0] else q[1] for q in quoted if (q[0] or q[1])]\n",
        "        if quoted_flat:\n",
        "            return [normalize_quotes(x).strip() for x in quoted_flat if x.strip()]\n",
        "        # else: maybe it's a single long string (no commas / no separate quoted utterances)\n",
        "        # treat inner as one long string and split into sentences\n",
        "        return split_into_sentences_by_regex(inner)\n",
        "\n",
        "    # If it doesn't look like bracketed list\n",
        "    #working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRvkS6q1rWbC"
      },
      "outputs": [],
      "source": [
        "#11\n",
        "import pandas as pd\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/dailydialog.csv\"  # change if inside folder\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(df.head())\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttuZaRYqrXOp"
      },
      "outputs": [],
      "source": [
        "#12\n",
        "# Robust parser for dialog/act/emotion columns and flatten to utterance-level df\n",
        "import ast, re\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "import nltk\n",
        "\n",
        "# If you don't have nltk punkt tokenizer installed, uncomment:\n",
        "# nltk.download('punkt')\n",
        "\n",
        "def normalize_quotes(s: str) -> str:\n",
        "    \"\"\"Replace curly quotes and weird unicode apostrophes with ASCII equivalents.\"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "    s = s.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
        "    s = s.replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \"-\")\n",
        "    return s\n",
        "\n",
        "def try_literal_eval(s: str):\n",
        "    \"\"\"Try to parse a string with ast.literal_eval, safely returning None if it fails.\"\"\"\n",
        "    try:\n",
        "        return ast.literal_eval(s)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# Sentence splitter fallback: splits on punctuation (.!?)+ whitespace; preserves abbreviations badly but OK for dialogues.\n",
        "sent_split_re = re.compile(r'(?<=[.!?])\\s+')\n",
        "\n",
        "def split_into_sentences_by_regex(text: str) -> List[str]:\n",
        "    \"\"\"Fallback: split a long string into sentences by punctuation-based regex.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    # normalize multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    parts = re.split(sent_split_re, text)\n",
        "    # strip and remove empty parts\n",
        "    parts = [p.strip() for p in parts if p.strip()]\n",
        "    return parts\n",
        "\n",
        "def parse_possible_dialog_field(raw):\n",
        "    \"\"\"\n",
        "    Given raw value from 'dialog' column, return a list of utterances.\n",
        "    Handles:\n",
        "      - Proper python list string -> ast.literal_eval\n",
        "      - Single-quoted long string -> split by sentence boundary\n",
        "      - Already a list -> return as-is\n",
        "    \"\"\"\n",
        "    if raw is None:\n",
        "        return []\n",
        "    # If it's already a list\n",
        "    if isinstance(raw, list):\n",
        "        return [str(x).strip() for x in raw if str(x).strip()]\n",
        "\n",
        "    # Normalize quotes and whitespace first\n",
        "    s = normalize_quotes(str(raw)).strip()\n",
        "\n",
        "    # Try literal_eval directly (works if it's like \"['utt1', 'utt2']\" or \"['utt1' 'utt2']\" sometimes)\n",
        "    parsed = try_literal_eval(s)\n",
        "    if isinstance(parsed, list):\n",
        "        return [str(x).strip() for x in parsed if str(x).strip()]\n",
        "\n",
        "    # If literal_eval failed: check for pattern where numbers or tokens are space-separated like \"[3 2 3]\" etc.\n",
        "    # For numeric lists (act/emotion) we'll handle elsewhere. For dialog, we check if s starts with [ and ends with ].\n",
        "    if s.startswith('[') and s.endswith(']'):\n",
        "        inner = s[1:-1].strip()\n",
        "        # If inner contains quotes somewhere, try to extract quoted substrings\n",
        "        quoted = re.findall(r\"'(.*?)'|\\\"(.*?)\\\"\", inner)\n",
        "        # quoted is list of tuples: (group1, group2). extract non-empty and strip\n",
        "        quoted_flat = [q[0] if q[0] else q[1] for q in quoted if (q[0] or q[1])]\n",
        "        if quoted_flat:\n",
        "            return [normalize_quotes(x).strip() for x in quoted_flat if x.strip()]\n",
        "        # else: maybe it's a single long string (no commas / no separate quoted utterances)\n",
        "        # treat inner as one long string and split into sentences\n",
        "        return split_into_sentences_by_regex(inner)\n",
        "\n",
        "    # If it doesn't look like bracketed list at all, maybe it is just a multi-sentence string\n",
        "    return split_into_sentences_by_regex(s)\n",
        "\n",
        "def parse_numeric_list_field(raw):\n",
        "    \"\"\"\n",
        "    Parse act/emotion field that might be:\n",
        "      - already a list of ints\n",
        "      - a string like '[1 2 3 4]' (space-separated)\n",
        "      - a string like '[1,2,3,4]' (comma-separated)\n",
        "      - a string like '1 2 3 4'\n",
        "    Returns list of ints.\n",
        "    \"\"\"\n",
        "    if raw is None:\n",
        "        return []\n",
        "    if isinstance(raw, list):\n",
        "        # convert elements to ints if possible\n",
        "        out = []\n",
        "        for x in raw:\n",
        "            try:\n",
        "                out.append(int(x))\n",
        "            except Exception:\n",
        "                # try strip and then int\n",
        "                try:\n",
        "                    out.append(int(str(x).strip()))\n",
        "                except Exception:\n",
        "                    pass\n",
        "        return out\n",
        "\n",
        "    s = normalize_quotes(str(raw)).strip()\n",
        "    # strip brackets\n",
        "    if s.startswith('[') and s.endswith(']'):\n",
        "        s = s[1:-1].strip()\n",
        "\n",
        "    # try comma split first\n",
        "    if ',' in s:\n",
        "        parts = [p.strip() for p in s.split(',') if p.strip()]\n",
        "    else:\n",
        "        # split on whitespace\n",
        "        parts = [p.strip() for p in re.split(r'\\s+', s) if p.strip()]\n",
        "\n",
        "    out = []\n",
        "    for p in parts:\n",
        "        try:\n",
        "            out.append(int(p))\n",
        "        except Exception:\n",
        "            # try to remove any non-digit chars and parse\n",
        "            p_clean = re.sub(r'[^\\d-]', '', p)\n",
        "            if p_clean:\n",
        "                try:\n",
        "                    out.append(int(p_clean))\n",
        "                except:\n",
        "                    pass\n",
        "    return out\n",
        "\n",
        "# Now apply parsing to your DataFrame 'data' safely and flatten\n",
        "def flatten_dataframe_to_utterances(df):\n",
        "    utterances = []\n",
        "    emotions = []\n",
        "    acts = []\n",
        "    source_row_idx = []  # keep track of which conversation row they came from\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        raw_dialog = row['dialog']\n",
        "        raw_act = row.get('act', None)\n",
        "        raw_emotion = row.get('emotion', None)\n",
        "\n",
        "        dialog_list = parse_possible_dialog_field(raw_dialog)\n",
        "        act_list = parse_numeric_list_field(raw_act)\n",
        "        emo_list = parse_numeric_list_field(raw_emotion)\n",
        "\n",
        "        # If emotion/act lists are empty but dialog_list has sentences, we can either skip or assign -1\n",
        "        if emo_list and len(emo_list) != len(dialog_list):\n",
        "            # Attempt heuristics: sometimes emo_list is longer (multiple conversations collapsed) or shorter.\n",
        "            # If emo_list length is 1 and dialog_list >1 -> assume same label for all utterances\n",
        "            if len(emo_list) == 1:\n",
        "                emo_list = emo_list * len(dialog_list)\n",
        "            else:\n",
        "                # if lengths mismatch, prefer length of dialog_list; pad with last label or -1\n",
        "                if len(emo_list) < len(dialog_list):\n",
        "                    # pad with last value\n",
        "                    emo_list = emo_list + [emo_list[-1]] * (len(dialog_list) - len(emo_list))\n",
        "                else:\n",
        "                    # truncate emo_list\n",
        "                    emo_list = emo_list[:len(dialog_list)]\n",
        "\n",
        "        if act_list and len(act_list) != len(dialog_list):\n",
        "            if len(act_list) == 1:\n",
        "                act_list = act_list * len(dialog_list)\n",
        "            else:\n",
        "                if len(act_list) < len(dialog_list):\n",
        "                    act_list = act_list + [act_list[-1]] * (len(dialog_list) - len(act_list))\n",
        "                else:\n",
        "                    act_list = act_list[:len(dialog_list)]\n",
        "\n",
        "        # If emo_list is still empty, assign -1 placeholders\n",
        "        if not emo_list:\n",
        "            emo_list = [-1] * len(dialog_list)\n",
        "        if not act_list:\n",
        "            act_list = [-1] * len(dialog_list)\n",
        "\n",
        "        for utt, a, e in zip(dialog_list, act_list, emo_list):\n",
        "            utterances.append(utt)\n",
        "            acts.append(a)\n",
        "            emotions.append(e)\n",
        "            source_row_idx.append(idx)\n",
        "\n",
        "    out_df = pd.DataFrame({\n",
        "        'utterance': utterances,\n",
        "        'act': acts,\n",
        "        'emotion': emotions,\n",
        "        'source_idx': source_row_idx\n",
        "    })\n",
        "    return out_df\n",
        "\n",
        "# Usage:\n",
        "# data is your original DataFrame loaded from CSV\n",
        "# safe: make a shallow copy if you want to keep original\n",
        "parsed_df = flatten_dataframe_to_utterances(df)\n",
        "print(parsed_df.head())\n",
        "print(\"Counts:\", parsed_df.shape)\n",
        "# Quick checks\n",
        "print(parsed_df['emotion'].value_counts(dropna=False).head())\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koy4-gMysEet"
      },
      "outputs": [],
      "source": [
        "#13\n",
        "parsed_df = flatten_dataframe_to_utterances(df)\n",
        "#working cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqYYzVvAsIve"
      },
      "outputs": [],
      "source": [
        "#14\n",
        "print(parsed_df.head())\n",
        "print(parsed_df.shape)\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuO9uUBmshAI"
      },
      "outputs": [],
      "source": [
        "#15\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()                       # lowercase\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s']\", \" \", text)  # remove special chars, keep apostrophes\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()      # remove extra spaces\n",
        "    return text\n",
        "\n",
        "parsed_df['utterance_clean'] = parsed_df['utterance'].apply(clean_text)\n",
        "\n",
        "# Quick check\n",
        "print(parsed_df[['utterance', 'utterance_clean', 'emotion']].head())\n",
        "#working cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9Q2_6lTsmCp"
      },
      "outputs": [],
      "source": [
        "#16\n",
        "emotion_map = {0:'neutral',1:'anger',2:'disgust',3:'fear',4:'happy',5:'sad',6:'surprise'}\n",
        "parsed_df['emotion_text'] = parsed_df['emotion'].map(emotion_map)\n",
        "\n",
        "# Check distribution\n",
        "print(parsed_df['emotion_text'].value_counts())\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ1IElVtsqPI"
      },
      "outputs": [],
      "source": [
        "#17\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    parsed_df['utterance_clean'], parsed_df['emotion'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=parsed_df['emotion']   # maintain class distribution\n",
        ")\n",
        "#working cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF8CYMoFsuSK"
      },
      "outputs": [],
      "source": [
        "#18\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=64)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=64)\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvJ5Y19vs7wQ"
      },
      "outputs": [],
      "source": [
        "#19\n",
        "import torch\n",
        "\n",
        "train_labels_tensor = torch.tensor(list(train_labels))\n",
        "test_labels_tensor = torch.tensor(list(test_labels))\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdILOlcEtFK4"
      },
      "outputs": [],
      "source": [
        "# 20 training the model#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90TSITRzvJZ_"
      },
      "outputs": [],
      "source": [
        "#21\n",
        "!pip install torch transformers scikit-learn\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-TyReTCvOgY"
      },
      "outputs": [],
      "source": [
        "#22\n",
        "#import libraries\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW  # Correct import\n",
        "from sklearn.metrics import f1_score\n",
        "#working cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oraX52ivvzub"
      },
      "outputs": [],
      "source": [
        "#23\n",
        "#creating a pytorch dataset\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # returns input_ids, attention_mask, and label for each item\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "# Create train and test datasets\n",
        "train_dataset = EmotionDataset(train_encodings, train_labels_tensor)\n",
        "test_dataset = EmotionDataset(test_encodings, test_labels_tensor)\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLROfBpkv51m"
      },
      "outputs": [],
      "source": [
        "#24\n",
        "#creating dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRvuvTzUv-hX"
      },
      "outputs": [],
      "source": [
        "#25\n",
        "#initialising bert model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=7  # 7 emotion classes: neutral, anger, disgust, fear, happy, sad, surprise\n",
        ")\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "#working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJT3bpbPwISS"
      },
      "outputs": [],
      "source": [
        "#26\n",
        "#define optimiser\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "#working cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFwwhyXewNF6"
      },
      "outputs": [],
      "source": [
        "#27\n",
        "#training loop\n",
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in loop:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_description(f'Epoch {epoch+1}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1} finished. Average Loss: {total_loss/len(train_loader):.4f}\")\n",
        "    #working cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0GXg_6wDJcL"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        preds.extend(predictions.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute F1-score per class\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(true_labels, preds, target_names=[\n",
        "    'neutral','anger','disgust','fear','happy','sad','surprise'\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX7VUmpmFQ8g"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "parsed_df['emotion_text'].value_counts().plot(kind='bar', title='Emotion Distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1️⃣ Mount Google Drive & Load Dataset\n",
        "# ===============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "csv_path = \"/content/drive/MyDrive/dailydialog.csv\"  # change if needed\n",
        "df = pd.read_csv(csv_path)\n",
        "print(df.head())\n",
        "print(df.shape)\n",
        "\n",
        "# ===============================\n",
        "# 2️⃣ Preprocessing Utilities\n",
        "# ===============================\n",
        "import ast, re\n",
        "from typing import List\n",
        "\n",
        "def normalize_quotes(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "    s = s.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
        "    s = s.replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \"-\")\n",
        "    return s\n",
        "\n",
        "def try_literal_eval(s: str):\n",
        "    try:\n",
        "        return ast.literal_eval(s)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "sent_split_re = re.compile(r'(?<=[.!?])\\s+')\n",
        "def split_into_sentences_by_regex(text: str) -> List[str]:\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    parts = re.split(sent_split_re, text)\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "def parse_possible_dialog_field(raw):\n",
        "    if raw is None:\n",
        "        return []\n",
        "    if isinstance(raw, list):\n",
        "        return [str(x).strip() for x in raw if str(x).strip()]\n",
        "    s = normalize_quotes(str(raw)).strip()\n",
        "    parsed = try_literal_eval(s)\n",
        "    if isinstance(parsed, list):\n",
        "        return [str(x).strip() for x in parsed if str(x).strip()]\n",
        "    if s.startswith('[') and s.endswith(']'):\n",
        "        inner = s[1:-1].strip()\n",
        "        quoted = re.findall(r\"'(.*?)'|\\\"(.*?)\\\"\", inner)\n",
        "        quoted_flat = [q[0] if q[0] else q[1] for q in quoted if (q[0] or q[1])]\n",
        "        if quoted_flat:\n",
        "            return [normalize_quotes(x).strip() for x in quoted_flat if x.strip()]\n",
        "        return split_into_sentences_by_regex(inner)\n",
        "    return split_into_sentences_by_regex(s)\n",
        "\n",
        "def parse_numeric_list_field(raw):\n",
        "    if raw is None:\n",
        "        return []\n",
        "    if isinstance(raw, list):\n",
        "        out = []\n",
        "        for x in raw:\n",
        "            try: out.append(int(x))\n",
        "            except: pass\n",
        "        return out\n",
        "    s = normalize_quotes(str(raw)).strip()\n",
        "    if s.startswith('[') and s.endswith(']'):\n",
        "        s = s[1:-1].strip()\n",
        "    parts = [p.strip() for p in re.split(r'[,\\s]+', s) if p.strip()]\n",
        "    out = []\n",
        "    for p in parts:\n",
        "        try: out.append(int(p))\n",
        "        except:\n",
        "            p_clean = re.sub(r'[^\\d-]', '', p)\n",
        "            if p_clean:\n",
        "                try: out.append(int(p_clean))\n",
        "                except: pass\n",
        "    return out\n",
        "\n",
        "def flatten_dataframe_to_utterances(df):\n",
        "    utterances, emotions, acts, source_idx = [], [], [], []\n",
        "    for idx, row in df.iterrows():\n",
        "        dialog_list = parse_possible_dialog_field(row['dialog'])\n",
        "        act_list = parse_numeric_list_field(row.get('act', None))\n",
        "        emo_list = parse_numeric_list_field(row.get('emotion', None))\n",
        "\n",
        "        if emo_list and len(emo_list) != len(dialog_list):\n",
        "            if len(emo_list) == 1:\n",
        "                emo_list *= len(dialog_list)\n",
        "            else:\n",
        "                if len(emo_list) < len(dialog_list):\n",
        "                    emo_list += [emo_list[-1]] * (len(dialog_list)-len(emo_list))\n",
        "                else:\n",
        "                    emo_list = emo_list[:len(dialog_list)]\n",
        "\n",
        "        if act_list and len(act_list) != len(dialog_list):\n",
        "            if len(act_list) == 1:\n",
        "                act_list *= len(dialog_list)\n",
        "            else:\n",
        "                if len(act_list) < len(dialog_list):\n",
        "                    act_list += [act_list[-1]] * (len(dialog_list)-len(act_list))\n",
        "                else:\n",
        "                    act_list = act_list[:len(dialog_list)]\n",
        "\n",
        "        if not emo_list: emo_list = [-1]*len(dialog_list)\n",
        "        if not act_list: act_list = [-1]*len(dialog_list)\n",
        "\n",
        "        for utt, a, e in zip(dialog_list, act_list, emo_list):\n",
        "            utterances.append(utt)\n",
        "            acts.append(a)\n",
        "            emotions.append(e)\n",
        "            source_idx.append(idx)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'utterance': utterances,\n",
        "        'act': acts,\n",
        "        'emotion': emotions,\n",
        "        'source_idx': source_idx\n",
        "    })\n",
        "\n",
        "parsed_df = flatten_dataframe_to_utterances(df)\n",
        "\n",
        "# ===============================\n",
        "# 3️⃣ Clean Text\n",
        "# ===============================\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s']\", \" \", text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "parsed_df['utterance_clean'] = parsed_df['utterance'].apply(clean_text)\n",
        "\n",
        "# Map emotion IDs to text\n",
        "emotion_map = {0:'neutral',1:'anger',2:'disgust',3:'fear',4:'happy',5:'sad',6:'surprise'}\n",
        "parsed_df['emotion_text'] = parsed_df['emotion'].map(emotion_map)\n",
        "\n",
        "# ===============================\n",
        "# 4️⃣ Train-Test Split\n",
        "# ===============================\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    parsed_df['utterance_clean'], parsed_df['emotion'],\n",
        "    test_size=0.2, random_state=42, stratify=parsed_df['emotion']\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 5️⃣ Tokenization (DistilBERT)\n",
        "# ===============================\n",
        "!pip install transformers torch scikit-learn --quiet\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=64)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=64)\n",
        "\n",
        "import torch\n",
        "train_labels_tensor = torch.tensor(list(train_labels))\n",
        "test_labels_tensor = torch.tensor(list(test_labels))\n",
        "\n",
        "# ===============================\n",
        "# 6️⃣ PyTorch Dataset & DataLoader\n",
        "# ===============================\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = EmotionDataset(train_encodings, train_labels_tensor)\n",
        "test_dataset = EmotionDataset(test_encodings, test_labels_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # larger batch for speed\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# ===============================\n",
        "# 7️⃣ Model & Optimizer\n",
        "# ===============================\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=7\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# ===============================\n",
        "# 8️⃣ Training Loop (Mixed Precision)\n",
        "# ===============================\n",
        "from tqdm import tqdm\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    total_loss = 0\n",
        "    for batch in loop:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_description(f'Epoch {epoch+1}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    print(f\"Epoch {epoch+1} finished. Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# ===============================\n",
        "# 9️⃣ Evaluation\n",
        "# ===============================\n",
        "model.eval()\n",
        "preds, true_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        preds.extend(predictions.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy = accuracy_score(true_labels, preds)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "print(classification_report(true_labels, preds, target_names=[\n",
        "    'neutral','anger','disgust','fear','happy','sad','surprise'\n",
        "]))\n",
        "\n",
        "# ===============================\n",
        "# 10️⃣ Emotion Distribution Plot\n",
        "# ===============================\n",
        "import matplotlib.pyplot as plt\n",
        "parsed_df['emotion_text'].value_counts().plot(kind='bar', title='Emotion Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "evZzt_v2RV2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# 1️⃣ Separate majority and minority classes\n",
        "dfs = []\n",
        "target_count = 2000  # desired number of samples per class\n",
        "\n",
        "for emotion in parsed_df['emotion_text'].unique():\n",
        "    df_class = parsed_df[parsed_df['emotion_text'] == emotion]\n",
        "    if len(df_class) < target_count:\n",
        "        # Oversample minority class\n",
        "        df_class_upsampled = resample(\n",
        "            df_class,\n",
        "            replace=True,\n",
        "            n_samples=target_count,\n",
        "            random_state=42\n",
        "        )\n",
        "    else:\n",
        "        df_class_upsampled = df_class.sample(n=target_count, random_state=42)\n",
        "    dfs.append(df_class_upsampled)\n",
        "\n",
        "# 2️⃣ Combine all classes\n",
        "df_balanced = pd.concat(dfs).reset_index(drop=True)\n",
        "\n",
        "# 3️⃣ Shuffle the dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check distribution\n",
        "print(df_balanced['emotion_text'].value_counts())\n"
      ],
      "metadata": {
        "id": "BxxcRzUzdeFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df_balanced['utterance_clean'], df_balanced['emotion'],\n",
        "    test_size=0.2, random_state=42, stratify=df_balanced['emotion']\n",
        ")"
      ],
      "metadata": {
        "id": "2v7Vp5SbdizF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1️⃣ Tokenization (DistilBERT)\n",
        "# ===============================\n",
        "from transformers import DistilBertTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=64)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=64)\n",
        "\n",
        "train_labels_tensor = torch.tensor(list(train_labels))\n",
        "test_labels_tensor = torch.tensor(list(test_labels))\n",
        "\n",
        "# ===============================\n",
        "# 2️⃣ PyTorch Dataset & DataLoader\n",
        "# ===============================\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = EmotionDataset(train_encodings, train_labels_tensor)\n",
        "test_dataset = EmotionDataset(test_encodings, test_labels_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# ===============================\n",
        "# 3️⃣ Model & Optimizer\n",
        "# ===============================\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=7\n",
        ")\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# ===============================\n",
        "# 4️⃣ Training Loop (Mixed Precision)\n",
        "# ===============================\n",
        "from tqdm import tqdm\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    total_loss = 0\n",
        "    for batch in loop:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_description(f'Epoch {epoch+1}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    print(f\"Epoch {epoch+1} finished. Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# ===============================\n",
        "# 5️⃣ Evaluation: Accuracy + F1 + Confusion Matrix\n",
        "# ===============================\n",
        "model.eval()\n",
        "preds, true_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        preds.extend(predictions.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(true_labels, preds)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\\n\")\n",
        "\n",
        "# F1-score per class\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(true_labels, preds, target_names=[\n",
        "    'neutral','anger','disgust','fear','happy','sad','surprise'\n",
        "]))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(true_labels, preds)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d',\n",
        "            xticklabels=['neutral','anger','disgust','fear','happy','sad','surprise'],\n",
        "            yticklabels=['neutral','anger','disgust','fear','happy','sad','surprise'],\n",
        "            cmap=\"Blues\")\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Emotion Distribution Plot\n",
        "plt.figure(figsize=(8,5))\n",
        "df_balanced['emotion_text'].value_counts().plot(kind='bar', title='Balanced Emotion Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yndOR9dFgSh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#newcode"
      ],
      "metadata": {
        "id": "MRMNi7VDHSL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "epochs = 30\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    total_loss = 0\n",
        "    for batch in loop:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_description(f'Epoch {epoch+1}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    print(f\"Epoch {epoch+1} finished. Avg Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "ptrDEBNlTD19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 5️⃣ Evaluation: Accuracy + F1 + Confusion Matrix - 30 epochs\n",
        "# ===============================\n",
        "model.eval()\n",
        "preds, true_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        preds.extend(predictions.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(true_labels, preds)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\\n\")\n",
        "\n",
        "# F1-score per class\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(true_labels, preds, target_names=[\n",
        "    'neutral','anger','disgust','fear','happy','sad','surprise'\n",
        "]))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(true_labels, preds)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d',\n",
        "            xticklabels=['neutral','anger','disgust','fear','happy','sad','surprise'],\n",
        "            yticklabels=['neutral','anger','disgust','fear','happy','sad','surprise'],\n",
        "            cmap=\"Blues\")\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Emotion Distribution Plot\n",
        "plt.figure(figsize=(8,5))\n",
        "df_balanced['emotion_text'].value_counts().plot(kind='bar', title='Balanced Emotion Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HceJbh6rWoMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conference"
      ],
      "metadata": {
        "id": "3CCXCgrSgEpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Dependencies\n",
        "!pip install transformers torch scikit-learn seaborn --quiet\n"
      ],
      "metadata": {
        "id": "JLDRJGXdjUWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports'\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import (\n",
        "    BertTokenizer, BertForSequenceClassification,\n",
        "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
        "    RobertaTokenizer, RobertaForSequenceClassification,\n",
        "    AlbertTokenizer, AlbertForSequenceClassification,\n",
        "    XLNetTokenizer, XLNetForSequenceClassification\n",
        ")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "tcoxQC1qjuOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Oversampled Dataset\n",
        "# If previously saved:\n",
        "# df_balanced = pd.read_csv(\"/content/drive/MyDrive/df_balanced.csv\")\n",
        "\n",
        "df_balanced.head()\n"
      ],
      "metadata": {
        "id": "g_Lu9YYmjzLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train/Test Split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df_balanced[\"utterance_clean\"],\n",
        "    df_balanced[\"emotion\"],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_balanced[\"emotion\"]\n",
        ")\n",
        "\n",
        "train_labels = list(train_labels)\n",
        "test_labels = list(test_labels)\n"
      ],
      "metadata": {
        "id": "KFleJa1qj526"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Class\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "O_WBIvdukBG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Universal Transformer Trainer (With Curves + Confusion Matrices)\n",
        "def train_transformer(model_name, tokenizer, model_class, epochs):\n",
        "\n",
        "    print(f\"\\n====================\")\n",
        "    print(f\" Training {model_name} for {epochs} epochs\")\n",
        "    print(f\"====================\\n\")\n",
        "\n",
        "    # Tokenize\n",
        "    train_enc = tokenizer(list(train_texts), truncation=True, padding=True, max_length=64)\n",
        "    test_enc = tokenizer(list(test_texts), truncation=True, padding=True, max_length=64)\n",
        "\n",
        "    train_dataset = EmotionDataset(train_enc, train_labels)\n",
        "    test_dataset = EmotionDataset(test_enc, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model_class.from_pretrained(model_name, num_labels=7).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    # Stores\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(ids, attention_mask=mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_losses.append(total_loss / len(train_loader))\n",
        "        train_accs.append(correct / total)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        v_correct = 0\n",
        "        v_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                ids = batch[\"input_ids\"].to(device)\n",
        "                mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = model(ids, attention_mask=mask, labels=labels)\n",
        "                val_loss += outputs.loss.item()\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "                v_correct += (preds == labels).sum().item()\n",
        "                v_total += labels.size(0)\n",
        "\n",
        "        val_losses.append(val_loss / len(test_loader))\n",
        "        val_accs.append(v_correct / v_total)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: TrainLoss={train_losses[-1]:.4f}, ValLoss={val_losses[-1]:.4f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    preds, truth = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            out = model(ids, attention_mask=mask)\n",
        "            pred = torch.argmax(out.logits, dim=1)\n",
        "\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            truth.extend(labels.cpu().numpy())\n",
        "\n",
        "    report = classification_report(\n",
        "        truth, preds,\n",
        "        output_dict=True,\n",
        "        target_names=['neutral','anger','disgust','fear','happy','sad','surprise']\n",
        "    )\n",
        "    accuracy = accuracy_score(truth, preds)\n",
        "\n",
        "    # Plots: Loss Curves\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Val Loss\")\n",
        "    plt.title(f\"{model_name} Loss Curve ({epochs} epochs)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy Curves\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(train_accs, label=\"Train Acc\")\n",
        "    plt.plot(val_accs, label=\"Val Acc\")\n",
        "    plt.title(f\"{model_name} Accuracy Curve ({epochs} epochs)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # -----------------------------\n",
        "    # CONFUSION MATRIX (Counts + Percentages)\n",
        "    # -----------------------------\n",
        "    classes = ['neutral','anger','disgust','fear','happy','sad','surprise']\n",
        "    cm = confusion_matrix(truth, preds)\n",
        "\n",
        "    # Raw counts\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(f\"{model_name} Confusion Matrix (Counts)\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "    # Percentages\n",
        "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    cm_percent = np.round(cm_percent * 100, 2)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sns.heatmap(cm_percent, annot=True, fmt='.2f', cmap='Greens',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(f\"{model_name} Confusion Matrix (Percentages)\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, report\n"
      ],
      "metadata": {
        "id": "EzrghRrVkGdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM/RNN/NN Models\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab=30000, embed_dim=128, hidden=128, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        _, (h, _) = self.lstm(x)\n",
        "        return self.fc(h[-1])\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab=30000, embed_dim=128, hidden=128, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        _, h = self.rnn(x)\n",
        "        return self.fc(h[-1])\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, vocab=30000, embed_dim=128, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab, embed_dim)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "pZPsdJZ_kM43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Non-Transformer Models (LSTM/RNN/NN)\n",
        "def train_simple_model(model, epochs):\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    train_ids = tokenizer(list(train_texts), truncation=True, padding='max_length',\n",
        "                          max_length=64, return_tensors=\"pt\")[\"input_ids\"]\n",
        "    test_ids  = tokenizer(list(test_texts), truncation=True, padding='max_length',\n",
        "                          max_length=64, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(train_ids, torch.tensor(train_labels))\n",
        "    test_dataset  = torch.utils.data.TensorDataset(test_ids, torch.tensor(test_labels))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for x, y in tqdm(train_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_losses.append(total_loss / len(train_loader))\n",
        "        train_accs.append(correct / total)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        v_correct = 0\n",
        "        v_total = 0\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                y_true.extend(y.cpu().numpy())\n",
        "                y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "                v_correct += (preds == y).sum().item()\n",
        "                v_total += y.size(0)\n",
        "\n",
        "        val_losses.append(val_loss / len(test_loader))\n",
        "        val_accs.append(v_correct / v_total)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: TrainLoss={train_losses[-1]:.4f}, ValLoss={val_losses[-1]:.4f}\")\n",
        "\n",
        "    # Loss curves\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Val Loss\")\n",
        "    plt.title(f\"{model.__class__.__name__} Loss Curve ({epochs} epochs)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy curves\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(train_accs, label=\"Train Accuracy\")\n",
        "    plt.plot(val_accs, label=\"Val Accuracy\")\n",
        "    plt.title(f\"{model.__class__.__name__} Accuracy Curve ({epochs} epochs)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # -----------------------------\n",
        "    # Confusion Matrix (Counts + Percentages)\n",
        "    # -----------------------------\n",
        "    classes = ['neutral','anger','disgust','fear','happy','sad','surprise']\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(f\"{model.__class__.__name__} Confusion Matrix (Counts)\")\n",
        "    plt.show()\n",
        "\n",
        "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    cm_percent = np.round(cm_percent * 100, 2)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sns.heatmap(cm_percent, annot=True, fmt='.2f', cmap='Greens',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(f\"{model.__class__.__name__} Confusion Matrix (Percentages)\")\n",
        "    plt.show()\n",
        "\n",
        "    return val_accs[-1]\n"
      ],
      "metadata": {
        "id": "FOWc_bEtkWne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run ALL Models for 5, 15, 30 Epochs\n",
        "results = []\n",
        "EPOCH_LIST = [5, 15, 30]\n",
        "\n",
        "transformer_models = {\n",
        "    \"BERT\": (BertTokenizer.from_pretrained(\"bert-base-uncased\"), BertForSequenceClassification, \"bert-base-uncased\"),\n",
        "    \"DistilBERT\": (DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\"), DistilBertForSequenceClassification, \"distilbert-base-uncased\"),\n",
        "    \"RoBERTa\": (RobertaTokenizer.from_pretrained(\"roberta-base\"), RobertaForSequenceClassification, \"roberta-base\"),\n",
        "    \"ALBERT\": (AlbertTokenizer.from_pretrained(\"albert-base-v2\"), AlbertForSequenceClassification, \"albert-base-v2\"),\n",
        "    \"XLNet\": (XLNetTokenizer.from_pretrained(\"xlnet-base-cased\"), XLNetForSequenceClassification, \"xlnet-base-cased\")\n",
        "}\n",
        "\n",
        "for name, (tok, cls, path) in transformer_models.items():\n",
        "    for epochs in EPOCH_LIST:\n",
        "        acc, rep = train_transformer(path, tok, cls, epochs)\n",
        "        results.append([name, epochs, acc, rep[\"macro avg\"][\"f1-score\"]])\n",
        "\n",
        "# LSTM, RNN, NN\n",
        "for epochs in EPOCH_LIST:\n",
        "    acc = train_simple_model(LSTMClassifier(), epochs)\n",
        "    results.append([\"LSTM\", epochs, acc, None])\n",
        "\n",
        "    acc = train_simple_model(RNNClassifier(), epochs)\n",
        "    results.append([\"RNN\", epochs, acc, None])\n",
        "\n",
        "    acc = train_simple_model(SimpleNN(), epochs)\n",
        "    results.append([\"SimpleNN\", epochs, acc, None])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kYcJTXKSkdBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(results, columns=[\n",
        "    \"Model\", \"Epochs\", \"Accuracy\", \"MacroF1\"\n",
        "])\n",
        "\n",
        "df_results\n"
      ],
      "metadata": {
        "id": "7uHDsXVtIwHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#improvements"
      ],
      "metadata": {
        "id": "YDJSjHzfYifN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def train_roberta_improved(model_name=\"roberta-large\", epochs=10):\n",
        "\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Increased sequence length\n",
        "    train_enc = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
        "    test_enc = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    train_dataset = EmotionDataset(train_enc, train_labels)\n",
        "    test_dataset = EmotionDataset(test_enc, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=7)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Layer-wise learning rates\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {\"params\": model.roberta.embeddings.parameters(), \"lr\": 1e-5},\n",
        "        {\"params\": model.roberta.encoder.layer[:12].parameters(), \"lr\": 2e-5},  # middle layers\n",
        "        {\"params\": model.classifier.parameters(), \"lr\": 5e-5}                    # top layers\n",
        "    ], weight_decay=0.01)\n",
        "\n",
        "    total_steps = len(train_loader) * epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=int(0.1 * total_steps),\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()  # AMP mixed precision\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = model(ids, attention_mask=mask, labels=labels)\n",
        "                loss = output.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    preds, truth = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            out = model(ids, attention_mask=mask)\n",
        "            pred = torch.argmax(out.logits, dim=1)\n",
        "\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            truth.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(truth, preds))\n",
        "\n",
        "    acc = accuracy_score(truth, preds)\n",
        "    print(f\"Final Accuracy: {acc:.4f}\")\n",
        "\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "FuFWsMKxXzlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#install dependencies\n",
        "!pip install transformers torch scikit-learn seaborn --quiet\n"
      ],
      "metadata": {
        "id": "unzFMrXoYkoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "from transformers import (\n",
        "    RobertaTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "FzBu-n2-YnNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Class\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "WqsRgZOrYqks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Improved RoBERTa-Large Training Code (Best Model)\n",
        "def train_roberta_large_improved(train_texts, train_labels, test_texts, test_labels,\n",
        "                                 model_name=\"roberta-large\",\n",
        "                                 max_len=128,\n",
        "                                 batch_size=16,\n",
        "                                 epochs=8):\n",
        "\n",
        "    print(\"Using model:\", model_name)\n",
        "    print(\"Training for\", epochs, \"epochs\")\n",
        "\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Longer sequence length (better for emotion detection)\n",
        "    train_enc = tokenizer(list(train_texts), truncation=True, padding=True, max_length=max_len)\n",
        "    test_enc = tokenizer(list(test_texts), truncation=True, padding=True, max_length=max_len)\n",
        "\n",
        "    train_dataset = EmotionDataset(train_enc, train_labels)\n",
        "    test_dataset = EmotionDataset(test_enc, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=7)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # ===== LAYER-WISE LEARNING RATE DECAY =====\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {\"params\": model.roberta.embeddings.parameters(), \"lr\": 1e-5},\n",
        "        {\"params\": model.roberta.encoder.layer[:12].parameters(), \"lr\": 2e-5},\n",
        "        {\"params\": model.classifier.parameters(), \"lr\": 5e-5},\n",
        "    ], weight_decay=0.01)\n",
        "\n",
        "    # ===== Warmup Scheduler =====\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=int(0.1 * total_steps),\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # ===== Mixed Precision for A100 =====\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    train_losses = []\n",
        "\n",
        "    # =======================\n",
        "    #       TRAINING\n",
        "    # =======================\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            ids = batch['input_ids'].to(device)\n",
        "            mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(ids, attention_mask=mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        epoch_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(epoch_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # =======================\n",
        "    #      EVALUATION\n",
        "    # =======================\n",
        "    model.eval()\n",
        "    preds, truth = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            out = model(ids, attention_mask=mask)\n",
        "            pred = torch.argmax(out.logits, dim=1)\n",
        "\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            truth.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        truth, preds,\n",
        "        target_names=['neutral','anger','disgust','fear','happy','sad','surprise']\n",
        "    ))\n",
        "\n",
        "    acc = accuracy_score(truth, preds)\n",
        "    print(f\"\\nFinal Accuracy: {acc:.4f}\")\n",
        "\n",
        "    # =======================\n",
        "    #  CONFUSION MATRIX\n",
        "    # =======================\n",
        "    cm = confusion_matrix(truth, preds)\n",
        "    labels = ['neutral','anger','disgust','fear','happy','sad','surprise']\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(\"Confusion Matrix (Counts)\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "    cm_pct = (cm.astype(\"float\") / cm.sum(axis=1)[:, None]) * 100\n",
        "    cm_pct = np.round(cm_pct, 2)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    sns.heatmap(cm_pct, annot=True, cmap='Greens', fmt='.2f', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(\"Confusion Matrix (Percentages)\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "VhQFLVKwZDLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run the best model\n",
        "acc = train_roberta_large_improved(\n",
        "    train_texts, train_labels,\n",
        "    test_texts, test_labels,\n",
        "    model_name=\"roberta-large\",\n",
        "    epochs=8   # 8 epochs is usually perfect for RoBERTa-large\n",
        ")\n",
        "\n",
        "print(\"Improved Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "_DPkdtZUZE-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#improving bert model from 95 accuracy"
      ],
      "metadata": {
        "id": "BBPnvmWV6sua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install + Imports\n",
        "!pip install transformers torch scikit-learn seaborn nltk --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "id": "Bo5332gV6rIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#light augmentation\n",
        "def augment_sentence(sentence, p=0.10):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "\n",
        "    for i, w in enumerate(words):\n",
        "        if np.random.rand() < p and wordnet.synsets(w):\n",
        "            syns = wordnet.synsets(w)\n",
        "            lemmas = [l.name().replace(\"_\", \" \") for syn in syns for l in syn.lemmas()]\n",
        "            if lemmas:\n",
        "                new_words[i] = np.random.choice(lemmas)\n",
        "\n",
        "    return \" \".join(new_words)\n"
      ],
      "metadata": {
        "id": "MaufY0i264iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset class\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, enc, labels):\n",
        "        self.enc = enc\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "RD0huoAZ69kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Improved BERT Training Code (Best Version)\n",
        "def train_bert_improved(train_texts, train_labels, test_texts, test_labels,\n",
        "                        model_name=\"bert-base-uncased\",\n",
        "                        max_len=256,\n",
        "                        batch_size=16,\n",
        "                        epochs=10):\n",
        "\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "    # AUGMENT TRAINING DATA LIGHTLY\n",
        "    aug_texts = []\n",
        "    aug_labels = []\n",
        "    for t, l in zip(train_texts, train_labels):\n",
        "        aug_texts.append(t)\n",
        "        aug_labels.append(l)\n",
        "\n",
        "        # add 1 augmented sample\n",
        "        aug_texts.append(augment_sentence(t))\n",
        "        aug_labels.append(l)\n",
        "\n",
        "    # TOKENIZE WITH LONGER SEQUENCES\n",
        "    train_enc = tokenizer(aug_texts, padding=True, truncation=True, max_length=max_len)\n",
        "    test_enc  = tokenizer(test_texts, padding=True, truncation=True, max_length=max_len)\n",
        "\n",
        "    train_dataset = EmotionDataset(train_enc, aug_labels)\n",
        "    test_dataset  = EmotionDataset(test_enc, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # LOAD MODEL\n",
        "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=7)\n",
        "    model.to(device)\n",
        "\n",
        "    # ==========================\n",
        "    # LAYER-WISE LEARNING RATES\n",
        "    # ==========================\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {\"params\": model.bert.embeddings.parameters(), \"lr\": 1e-5},\n",
        "        {\"params\": model.bert.encoder.layer[:8].parameters(), \"lr\": 2e-5},\n",
        "        {\"params\": model.bert.encoder.layer[8:].parameters(), \"lr\": 3e-5},\n",
        "        {\"params\": model.classifier.parameters(), \"lr\": 5e-5},\n",
        "    ], weight_decay=0.01)\n",
        "\n",
        "    total_steps = len(train_loader) * epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=int(0.1 * total_steps),\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # ==========================\n",
        "    #       TRAINING LOOP\n",
        "    # ==========================\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(ids, attention_mask=mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # ==========================\n",
        "    #       EVALUATION\n",
        "    # ==========================\n",
        "    preds, truth = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            out = model(ids, attention_mask=mask)\n",
        "            pred = torch.argmax(out.logits, dim=1)\n",
        "\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            truth.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        truth, preds,\n",
        "        target_names=['neutral','anger','disgust','fear','happy','sad','surprise']\n",
        "    ))\n",
        "\n",
        "    acc = accuracy_score(truth, preds)\n",
        "    print(\"\\nFINAL IMPROVED BERT ACCURACY:\", acc)\n",
        "\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "yYEyQe3_7B4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the Improved Best Model (BERT)\n",
        "acc = train_bert_improved(\n",
        "    train_texts, train_labels,\n",
        "    test_texts, test_labels,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "print(\"Improved BERT Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "dwkSAzGI7KWD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOuLpcSl/A6/bIj4TuWwzBl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}